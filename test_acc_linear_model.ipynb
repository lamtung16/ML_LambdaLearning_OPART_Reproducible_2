{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from utility_functions import SquaredHingeLoss\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from linear import LinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHs (edit these paths depending on dataset)\n",
    "dataset = 'detailed'\n",
    "\n",
    "# training data\n",
    "fold_path = 'training_data/' + dataset + '/folds.csv'\n",
    "inputs_path = 'training_data/' + dataset + '/inputs.csv'\n",
    "outputs_path = 'training_data/' + dataset + '/outputs.csv'\n",
    "evaluation_path = 'training_data/' + dataset + '/evaluation.csv'\n",
    "\n",
    "# raw dfs\n",
    "fold = 1\n",
    "fold_df = pd.read_csv(fold_path)\n",
    "inputs_df = pd.read_csv(inputs_path)\n",
    "outputs_df = pd.read_csv(outputs_path)\n",
    "evaluation_df = pd.read_csv(evaluation_path)\n",
    "\n",
    "# fold dfs\n",
    "inputs_fold1_df = inputs_df[inputs_df['sequenceID'].isin(fold_df[fold_df['fold'] == 1]['sequenceID'])]\n",
    "outputs_fold1_df = outputs_df[outputs_df['sequenceID'].isin(fold_df[fold_df['fold'] == 1]['sequenceID'])]\n",
    "\n",
    "# feature engineering transformation\n",
    "identity = lambda x: x\n",
    "log      = lambda x: np.log(x)\n",
    "loglog   = lambda x: np.log(np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_feature = ['length']\n",
    "f_engineering  = [loglog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_tensor(inputs_df, chosen_feature, f_engineer):\n",
    "    inputs = inputs_df[chosen_feature].to_numpy()\n",
    "    for i in range(len(f_engineer)):\n",
    "        inputs[:, i] = f_engineer[i](inputs[:, i])\n",
    "    inputs = torch.Tensor(inputs)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_training(inputs_df, outputs_df, chosen_feature, f_engineer, batch_size, margin, n_ites, verbose):\n",
    "    # inputs\n",
    "    inputs = inputs_df[chosen_feature].to_numpy()\n",
    "    for i in range(len(f_engineer)):\n",
    "        inputs[:, i] = f_engineer[i](inputs[:, i])\n",
    "    inputs = torch.Tensor(inputs)\n",
    "\n",
    "    # outputs:\n",
    "    targets_low  = torch.Tensor(outputs_df['min.log.lambda'].to_numpy().reshape(-1,1))\n",
    "    targets_high = torch.Tensor(outputs_df['max.log.lambda'].to_numpy().reshape(-1,1))\n",
    "    outputs = torch.cat((targets_low, targets_high), dim=1)\n",
    "\n",
    "    # prepare training dataset\n",
    "    dataset    = TensorDataset(inputs, outputs)\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=False)\n",
    "\n",
    "    # Instantiate model, loss function and optimizer\n",
    "    model = LinearModel(inputs.shape[1])\n",
    "    criterion = SquaredHingeLoss(margin)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Initialize early stopping parameters\n",
    "    best_loss = float('inf')\n",
    "    patience = 5  # Number of epochs to wait before early stopping\n",
    "    num_bad_epochs = 0\n",
    "\n",
    "    # Training loop\n",
    "    for i in range(n_ites):\n",
    "        for batch_input, batch_output in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(batch_input), batch_output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate validation loss\n",
    "        val_loss = criterion(model(inputs), outputs)\n",
    "\n",
    "        if verbose==1:\n",
    "            print(f\"{i}, loss: {val_loss}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            num_bad_epochs = 0\n",
    "        else:\n",
    "            num_bad_epochs += 1\n",
    "            if num_bad_epochs >= patience:\n",
    "                if verbose==1:\n",
    "                    print(f\"Stopping early at epoch {i}, loss: {val_loss}\")\n",
    "                break\n",
    "\n",
    "    return model, val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(model, inputs_fold1_df, outputs_fold1_df, chosen_feature, f_engineering):\n",
    "    prediction = model(get_input_tensor(inputs_fold1_df, chosen_feature, f_engineering)).detach().numpy()\n",
    "    min_log = outputs_fold1_df['min.log.lambda'].to_numpy().reshape(-1,1)\n",
    "    max_log = outputs_fold1_df['max.log.lambda'].to_numpy().reshape(-1,1)\n",
    "    min_margin = prediction - min_log\n",
    "    min_margin[np.isinf(min_margin)] = 0\n",
    "    max_margin = max_log - prediction\n",
    "    max_margin[np.isinf(max_margin)] = 0\n",
    "    criterion = min_margin.mean() + max_margin.mean()\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution(model, batch_size):\n",
    "    x = inputs_fold1_df[chosen_feature].to_numpy()\n",
    "    x = loglog(x)\n",
    "    y_start = outputs_fold1_df['min.log.lambda'].to_numpy()\n",
    "    y_end = outputs_fold1_df['max.log.lambda'].to_numpy()\n",
    "\n",
    "    # scatter\n",
    "    plt.scatter(x, y_start, color='r',   s=2, label='min.log.lambda')\n",
    "    plt.scatter(x, y_end,   color = 'b', s=2, label='max.log.lambda')\n",
    "\n",
    "    # solution\n",
    "    min_input = f_engineering[0](inputs_fold1_df[chosen_feature].min().item())\n",
    "    max_input = f_engineering[0](inputs_fold1_df[chosen_feature].max().item())\n",
    "    plt.plot([min_input, max_input], model(torch.Tensor([min_input, max_input]).reshape(-1, 1)).detach().numpy()[:,0])\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(chosen_feature[0])\n",
    "    plt.ylabel('target')\n",
    "\n",
    "    # legend\n",
    "    plt.legend()\n",
    "\n",
    "    # title\n",
    "    plt.title('batch_size=' + str(batch_size) + \"\\ncriterion=\" + str(round(get_criterion(model, inputs_fold1_df, outputs_fold1_df, chosen_feature, f_engineering), 2)))\n",
    "    \n",
    "    # Show plot\n",
    "    plt.grid(True)\n",
    "    plt.savefig('test_figure/' + str(batch_size) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER\n",
    "rows = []\n",
    "for batch_size in [1, 10, 20, 40, 100, 200, 400]:\n",
    "    for margin in [0, 1, 2]:\n",
    "        model, total_loss = linear_training(inputs_fold1_df, outputs_fold1_df, ['length'], [loglog], batch_size, margin, 500, 0)\n",
    "        criterion = round(get_criterion(model, inputs_fold1_df, outputs_fold1_df, chosen_feature, f_engineering), 3)\n",
    "        row = [batch_size, margin, criterion, total_loss]\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    batch_size  margin  criterion  total_loss\n",
      "16         200       1      2.074    0.465162\n",
      "15         200       0      2.085    0.131569\n",
      "13         100       1      2.134    0.459517\n",
      "12         100       0      2.144    0.129008\n",
      "10          40       1      2.173    0.458289\n",
      "19         400       1      2.182    0.458272\n",
      "7           20       1      2.183    0.458286\n",
      "9           40       0      2.185    0.128354\n",
      "4           10       1      2.188    0.458336\n",
      "6           20       0      2.196    0.128333\n",
      "18         400       0      2.197    0.128329\n",
      "3           10       0      2.199    0.128340\n",
      "17         200       2      2.238    1.352934\n",
      "0            1       0      2.248    0.129165\n",
      "1            1       1      2.263    0.462787\n",
      "14         100       2      2.272    1.349849\n",
      "11          40       2      2.294    1.349180\n",
      "20         400       2      2.298    1.349169\n",
      "8           20       2      2.299    1.349205\n",
      "5           10       2      2.305    1.349325\n",
      "2            1       2      2.386    1.359783\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(rows, columns=['batch_size', 'margin', 'criterion', 'total_loss'])\n",
    "print(df.sort_values(by='criterion'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
